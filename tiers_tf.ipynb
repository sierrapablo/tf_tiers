{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF de entrenamiento, con todas las variables y la columna tier completa\n",
    "df_train = pd.DataFrame(columns=(\"data\", \"tier\"))\n",
    "df_train.loc[0] = [50000, 1]\n",
    "df_train.loc[1] = [49000, 2]\n",
    "df_train.loc[2] = [40000, 2]\n",
    "df_train.loc[3] = [39000, 3]\n",
    "df_train.loc[4] = [30000, 3]\n",
    "df_train.loc[5] = [21000, 3]\n",
    "df_train.loc[6] = [20000, 4]\n",
    "df_train.loc[7] = [11000, 4]\n",
    "df_train.loc[8] = [10000, 5]\n",
    "\n",
    "\n",
    "# DF de test, con todas las variables y la columna tier completa\n",
    "df_test = pd.DataFrame(columns=(\"data\", \"tier\"))\n",
    "df_test.loc[0] = [80000, 1]\n",
    "df_test.loc[1] = [37000, 3]\n",
    "df_test.loc[2] = [32000, 3]\n",
    "df_test.loc[3] = [18000, 4]\n",
    "df_test.loc[4] = [500, 5]\n",
    "df_test.loc[5] = [200, 5]\n",
    "df_test.loc[6] = [45000, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y etiquetas\n",
    "X_train = df_train.drop('tier', axis=1)\n",
    "y_train = df_train['tier']\n",
    "\n",
    "X_test = df_test.drop('tier', axis=1)\n",
    "y_test = df_test['tier']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertir etiquetas a categorías\n",
    "y_train = to_categorical(y_train - 1, num_classes=5)\n",
    "y_test = to_categorical(y_test - 1, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1381 - loss: 1.6379 - val_accuracy: 0.0000e+00 - val_loss: 1.6546\n",
      "Epoch 2/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5363 - loss: 1.5716 - val_accuracy: 0.0000e+00 - val_loss: 1.6436\n",
      "Epoch 3/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2717 - loss: 1.5505 - val_accuracy: 0.0000e+00 - val_loss: 1.6472\n",
      "Epoch 4/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6717 - loss: 1.4750 - val_accuracy: 0.0000e+00 - val_loss: 1.6570\n",
      "Epoch 5/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3488 - loss: 1.5085 - val_accuracy: 0.0000e+00 - val_loss: 1.6507\n",
      "Epoch 6/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2717 - loss: 1.4700 - val_accuracy: 0.0000e+00 - val_loss: 1.6508\n",
      "Epoch 7/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4801 - loss: 1.4407 - val_accuracy: 0.0000e+00 - val_loss: 1.6630\n",
      "Epoch 8/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 1.3568 - val_accuracy: 0.0000e+00 - val_loss: 1.6970\n",
      "Epoch 9/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 1.3433 - val_accuracy: 0.0000e+00 - val_loss: 1.7145\n",
      "Epoch 10/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 1.3053 - val_accuracy: 0.0000e+00 - val_loss: 1.7419\n",
      "Epoch 11/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 1.2768 - val_accuracy: 0.0000e+00 - val_loss: 1.7693\n",
      "Epoch 12/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6908 - loss: 1.2736 - val_accuracy: 0.0000e+00 - val_loss: 1.7973\n",
      "Epoch 13/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4887 - loss: 1.2975 - val_accuracy: 0.0000e+00 - val_loss: 1.8057\n",
      "Epoch 14/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2866 - loss: 1.2648 - val_accuracy: 0.0000e+00 - val_loss: 1.8559\n",
      "Epoch 15/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6512 - loss: 1.1476 - val_accuracy: 0.0000e+00 - val_loss: 1.9351\n",
      "Epoch 16/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2866 - loss: 1.2068 - val_accuracy: 0.0000e+00 - val_loss: 1.9947\n",
      "Epoch 17/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3908 - loss: 1.2022 - val_accuracy: 0.0000e+00 - val_loss: 2.0488\n",
      "Epoch 18/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3595 - loss: 1.1631 - val_accuracy: 0.0000e+00 - val_loss: 2.1413\n",
      "Epoch 19/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6449 - loss: 1.0398 - val_accuracy: 0.0000e+00 - val_loss: 2.2394\n",
      "Epoch 20/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3908 - loss: 1.1134 - val_accuracy: 0.0000e+00 - val_loss: 2.3044\n",
      "Epoch 21/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5158 - loss: 1.0763 - val_accuracy: 0.0000e+00 - val_loss: 2.3923\n",
      "Epoch 22/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.9358 - val_accuracy: 0.0000e+00 - val_loss: 2.5391\n",
      "Epoch 23/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6762 - loss: 0.9817 - val_accuracy: 0.0000e+00 - val_loss: 2.6140\n",
      "Epoch 24/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.9540 - val_accuracy: 0.0000e+00 - val_loss: 2.7106\n",
      "Epoch 25/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6449 - loss: 0.9139 - val_accuracy: 0.0000e+00 - val_loss: 2.7974\n",
      "Epoch 26/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4470 - loss: 1.0204 - val_accuracy: 0.0000e+00 - val_loss: 2.8510\n",
      "Epoch 27/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7283 - loss: 0.8044 - val_accuracy: 0.0000e+00 - val_loss: 2.9249\n",
      "Epoch 28/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.8777 - val_accuracy: 0.0000e+00 - val_loss: 2.9607\n",
      "Epoch 29/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.8159 - val_accuracy: 0.0000e+00 - val_loss: 3.0460\n",
      "Epoch 30/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2866 - loss: 1.0237 - val_accuracy: 0.0000e+00 - val_loss: 3.0914\n",
      "Epoch 31/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.8313 - val_accuracy: 0.0000e+00 - val_loss: 3.1372\n",
      "Epoch 32/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4470 - loss: 0.9346 - val_accuracy: 0.0000e+00 - val_loss: 3.1774\n",
      "Epoch 33/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.8503 - val_accuracy: 0.0000e+00 - val_loss: 3.2302\n",
      "Epoch 34/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.8432 - val_accuracy: 0.0000e+00 - val_loss: 3.3116\n",
      "Epoch 35/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.7559 - val_accuracy: 0.0000e+00 - val_loss: 3.3775\n",
      "Epoch 36/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.6916 - val_accuracy: 0.0000e+00 - val_loss: 3.4530\n",
      "Epoch 37/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3845 - loss: 0.9697 - val_accuracy: 0.0000e+00 - val_loss: 3.4799\n",
      "Epoch 38/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5158 - loss: 0.8204 - val_accuracy: 0.0000e+00 - val_loss: 3.5254\n",
      "Epoch 39/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6137 - loss: 0.9111 - val_accuracy: 0.0000e+00 - val_loss: 3.5592\n",
      "Epoch 40/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4679 - loss: 0.8189 - val_accuracy: 0.0000e+00 - val_loss: 3.5768\n",
      "Epoch 41/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.7578 - val_accuracy: 0.0000e+00 - val_loss: 3.6555\n",
      "Epoch 42/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.7104 - val_accuracy: 0.0000e+00 - val_loss: 3.6806\n",
      "Epoch 43/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6762 - loss: 0.6500 - val_accuracy: 0.0000e+00 - val_loss: 3.7466\n",
      "Epoch 44/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.6656 - val_accuracy: 0.0000e+00 - val_loss: 3.8041\n",
      "Epoch 45/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3845 - loss: 0.8331 - val_accuracy: 0.0000e+00 - val_loss: 3.8148\n",
      "Epoch 46/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.7429 - val_accuracy: 0.0000e+00 - val_loss: 3.8459\n",
      "Epoch 47/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6762 - loss: 0.6813 - val_accuracy: 0.0000e+00 - val_loss: 3.8808\n",
      "Epoch 48/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.6730 - val_accuracy: 0.0000e+00 - val_loss: 3.9116\n",
      "Epoch 49/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5158 - loss: 0.7961 - val_accuracy: 0.0000e+00 - val_loss: 3.9204\n",
      "Epoch 50/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6658 - loss: 0.6687 - val_accuracy: 0.0000e+00 - val_loss: 3.9917\n",
      "Epoch 51/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5470 - loss: 0.7769 - val_accuracy: 0.0000e+00 - val_loss: 4.0147\n",
      "Epoch 52/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5929 - loss: 0.6344 - val_accuracy: 0.0000e+00 - val_loss: 4.0429\n",
      "Epoch 53/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4220 - loss: 0.8607 - val_accuracy: 0.0000e+00 - val_loss: 4.0854\n",
      "Epoch 54/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.8089 - val_accuracy: 0.0000e+00 - val_loss: 4.1066\n",
      "Epoch 55/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 0.8165 - val_accuracy: 0.5000 - val_loss: 4.1225\n",
      "Epoch 56/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.5839 - val_accuracy: 0.0000e+00 - val_loss: 4.1839\n",
      "Epoch 57/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 0.7705 - val_accuracy: 0.0000e+00 - val_loss: 4.2197\n",
      "Epoch 58/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5452 - loss: 0.7328 - val_accuracy: 0.5000 - val_loss: 4.2283\n",
      "Epoch 59/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5715 - val_accuracy: 0.5000 - val_loss: 4.2773\n",
      "Epoch 60/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7283 - loss: 0.7319 - val_accuracy: 0.5000 - val_loss: 4.3167\n",
      "Epoch 61/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 0.7114 - val_accuracy: 0.5000 - val_loss: 4.3348\n",
      "Epoch 62/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.7825 - val_accuracy: 0.5000 - val_loss: 4.3768\n",
      "Epoch 63/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4679 - loss: 0.7298 - val_accuracy: 0.5000 - val_loss: 4.3754\n",
      "Epoch 64/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3283 - loss: 0.7723 - val_accuracy: 0.5000 - val_loss: 4.3828\n",
      "Epoch 65/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.8040 - val_accuracy: 0.5000 - val_loss: 4.4376\n",
      "Epoch 66/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.7075 - val_accuracy: 0.5000 - val_loss: 4.4535\n",
      "Epoch 67/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 0.8074 - val_accuracy: 0.5000 - val_loss: 4.4841\n",
      "Epoch 68/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.7376 - val_accuracy: 0.5000 - val_loss: 4.5235\n",
      "Epoch 69/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.5700 - val_accuracy: 0.5000 - val_loss: 4.5651\n",
      "Epoch 70/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8619 - loss: 0.6759 - val_accuracy: 0.5000 - val_loss: 4.5783\n",
      "Epoch 71/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.6907 - val_accuracy: 0.5000 - val_loss: 4.6166\n",
      "Epoch 72/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3595 - loss: 0.7304 - val_accuracy: 0.5000 - val_loss: 4.6251\n",
      "Epoch 73/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 0.5700 - val_accuracy: 0.5000 - val_loss: 4.6631\n",
      "Epoch 74/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4679 - loss: 0.6483 - val_accuracy: 0.5000 - val_loss: 4.6727\n",
      "Epoch 75/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5036 - loss: 0.7033 - val_accuracy: 0.5000 - val_loss: 4.6815\n",
      "Epoch 76/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.7044 - val_accuracy: 0.5000 - val_loss: 4.7112\n",
      "Epoch 77/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.6432 - val_accuracy: 0.5000 - val_loss: 4.7376\n",
      "Epoch 78/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.5060 - val_accuracy: 0.5000 - val_loss: 4.7747\n",
      "Epoch 79/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7015 - loss: 0.7046 - val_accuracy: 0.5000 - val_loss: 4.8175\n",
      "Epoch 80/80\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5452 - loss: 0.6671 - val_accuracy: 0.5000 - val_loss: 4.8178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7143 - loss: 3.5914\n",
      "Loss: 3.5914227962493896, Accuracy: 0.7142857313156128\n"
     ]
    }
   ],
   "source": [
    "# Aquí te he hecho un entrenamiento con unos parámetros a ojo, pero es solo \n",
    "# una prueba.\n",
    "\n",
    "# Lo suyo sería que entrenaras con distintos epochs, validation_splits y \n",
    "# batch_size para encontrar el \"punto dulce\" de precisión del modelo.\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=80, validation_split=0.2, batch_size=1\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF con datos pero sin valor de tiers\n",
    "df_score = pd.DataFrame(columns=(\"data\",))\n",
    "\n",
    "df_score.loc[0] = [100000]\n",
    "df_score.loc[1] = [45500]\n",
    "df_score.loc[2] = [27900]\n",
    "df_score.loc[3] = [12000]\n",
    "df_score.loc[4] = [150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos de df_score\n",
    "X_score = df_score.values\n",
    "X_score = scaler.transform(X_score)\n",
    "\n",
    "# Predecir los tiers\n",
    "predictions = model.predict(X_score)\n",
    "predicted_tiers = predictions.argmax(axis=1) + 1\n",
    "\n",
    "# Añadir las predicciones a df_score\n",
    "df_score['predicted_tier'] = predicted_tiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>predicted_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data  predicted_tier\n",
       "0  100000               1\n",
       "1   45500               2\n",
       "2   27900               3\n",
       "3   12000               4\n",
       "4     150               4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
